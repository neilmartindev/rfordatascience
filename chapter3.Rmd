---
title: "R for Data Science Chapter 3: Data Transformation"
author: "Neil Martin"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true                # Enable Table of Contents
    toc_depth: 3             # Set depth of the TOC
    toc_float: true          # Move TOC
    number_sections: true    # Number the sections
    theme: cosmo             # Use a Bootstrap theme
    highlight: tango 
---

### Prerequisites

```{r setup}
library(nycflights13)
library(tidyverse)
library(ggplot2)
```

### dplyr basics

```{r example}

glimpse(flights)

flights |>
  filter(dest == "IAH") |>
  group_by(year, month, day) |>
  summarise(
    arr_delay = mean(arr_delay, na.rm = TRUE)
  )

```

### Rows

```{r rows}

# Flights that are more than 120 minutes late

flights |>
  filter(dep_delay > 120)

# Flights that departed on January 1st

flights |>
  filter(month == 1 & day == 1)

# Flights that departed in January or February

flights |>
  filter(month == 1 | month == 2)

# A shorter way to do the above

flights |>
  filter(month %in% c(1, 2))

jan1 <- flights |>
  filter(month == 1 & day == 1)

```

### arrange()

```{r arrange}

flights |>
  arrange(year, month, day, dep_time)

flights |> 
  arrange(desc(dep_delay))

```
### distinct()

```{r distinct}

# Remove any duplicate rows

flights |>
  distinct()

# Find all unique origin and destination pairs

flights |> 
  distinct(origin, dest)

flights |>
  count(origin, dest, sort = TRUE)

```
### Exercises

#### In a single pipeline for each condition, find all flights that meet the condition:

```{r exercise1}

flights |>
  filter(arr_delay > 120,
         dest %in% c("IAH", "HOU"),
         carrier %in% c("UA", "AA", "Dl"),
         month %in% c(7,8,9),
         arr_delay > 120 & dep_delay <=0,
         dep_delay >= 60 & (dep_delay - arr_delay) >= 30)

```
#### Sort flights to find the flights with the longest departure delays. Find the flights that left earliest in the morning.

```{r exercise2}

flights |> 
  arrange(desc(arr_delay)) |>
  head(10)

flights |>
  arrange(time_hour) |>
  head(10)

```

#### Sort flights to find the fastest flights. (Hint: Try including a math calculation inside of your function.)

```{r exercise3}

flights |>
  arrange((dep_time - arr_time)) |>
  head(10)

```
#### Was there a flight on every day of 2013?

```{r exercise4}

flights |>
  mutate(date = as.Date(time_hour)) |>
  group_by(date) |>
  summarise(n_flights = n()) |>
  summarise(total_days = n()) |>
  pull(total_days)
```

<p> Yes, there was a flight everyday in 2013. </p>

#### Which flights traveled the farthest distance? Which traveled the least distance?

```{r exercsie5}

flights |>
  arrange(distance)

```

<p> Flight 51 traveled the farthest distance and flight 1632 traveled the least. </p>

#### Does it matter what order you used filter() and arrange() if you’re using both? Why/why not? Think about the results and how much work the functions would have to do.

<p> I'd argue it is better practice to filter your dataset first before applying the arrange function. This reduces the numbers of rows that will be sorted by the arrange function. Doing this later seems inefficient.</p>

### The pipe

#### We’ve shown you simple examples of the pipe above, but its real power arises when you start to combine multiple verbs. For example, imagine that you wanted to find the fastest flights to Houston’s IAH airport: you need to combine filter(), mutate(), select(), and arrange():

```{r the_pipe}

flights |>
  filter(dest == "IAH") |>
  mutate(speed = distance / air_time * 60) |>
  select(year:day, dep_time, carrier, flight, speed) |>
  arrange(desc(speed))

 
```
#### Groups

```{r groups}

flights |> 
  group_by(month)

flights |> 
  group_by(month) |> 
  summarise(
    avg_delay = mean(dep_delay, na.rm = TRUE)
  )

flights |> 
  group_by(month) |> 
  summarise(
    avg_delay = mean(dep_delay, na.rm = TRUE),
    n = n ()
  )

flights |> 
  group_by(dest) |>
  slice_max(arr_delay, n = 1) |> 
  relocate(dest)

daily <- flights |> 
  group_by(year, month, day)

daily

daily_flights <- daily |> 
  summarise(n = n(),
            .groups = "drop_last"
  )

daily |> 
  ungroup()

daily |> 
  ungroup() |>
  summarise(
    avg_delay = mean(dep_delay, na.rm = TRUE),
    flights = n()
  )

flights |> 
  summarise(
    delay = mean(dep_delay, na.rm = TRUE),
    n = n(),
    .by = month
  )

```

### Exercises

#### Which carrier has the worst average delays? Challenge: can you disentangle the effects of bad airports vs. bad carriers? Why/why not? (Hint: think about flights |> group_by(carrier, dest) |> summarize(n()))

```{r exercises11}

flights |> 
  group_by(carrier) |>
  summarise(
    avg_delay = mean(dep_delay, na.rm = TRUE),
    n = n()
  ) |>
  arrange(avg_delay)

```

<p> The worst average delay was by the carrier F9 with an average delay of 20 minutes. </p>

#### Find the flights that are most delayed upon departure from each destination.

```{r exercise12}

flights |>
  filter(dep_delay > 0) |> 
  group_by(dest) |> 
  slice_max(dep_delay, n = 1) |> 
  relocate(dest)
```

#### How do delays vary over the course of the day? Illustrate your answer with a plot.

```{r exercise13}

flights |> 
  ggplot(aes(x = dep_time, y = dep_delay), na.rm = TRUE) +
  geom_point()

```
<p> There is a lot of delays around 5-10am and a noticeable trend of increased delays during the night.</p>

#### What happens if you supply a negative n to slice_min() and friends?

```{r exercise 14}

flights |>
  slice_min(dep_delay, n = -1)

```

<p> If a -1 is provided then just random observations are returned instead of being in order of the smallest first. </p>

####Explain what count() does in terms of the dplyr verbs you just learned. What does the sort argument to count() do?

```{r exercise15}

result <- flights |> 
    count(carrier, sort = TRUE)

result
```


<p> Count() counts the number of observations of a category within a dataframe. As shown above, it counts the number of times each carrier is shown within the dataframe.The sort argument allows the user to sort putting the largest value first. As shown the example, this shows us that UA has the most flights. </p>

#### Suppose we have the following tiny data frame:

```{r exercise 16}

df <- tibble(
  x = 1:5,
  y = c("a", "b", "a", "a", "b"),
  z = c("K", "K", "L", "L", "K")
)

df |> 
  group_by(y)

df |> 
  arrange(y)

df |> 
  group_by(y) |> 
  summarise(mean_x = mean(x))

df |>
  group_by(y, z) |>
  summarize(mean_x = mean(x))

df |>
  group_by(y, z) |>
  summarize(mean_x = mean(x), .groups = "drop")

df |>
  group_by(y, z) |>
  summarize(mean_x = mean(x))

df |>
  group_by(y, z) |>
  mutate(mean_x = mean(x))

```
<p> a) I think that grouping by Y will create two groups based on the letters present.

b) For the arrange, I predict that this will arrange the y column in alphabetical order.

c) This will calculate the mean of the x column and create a group based on the y column.

d) This will calculate the mean of the x column and create a group based on the y and z column.

e) This output will put a mean_x column in the dataframe and then ungroups the y and z groups.  

f) The first code runs and replaces the x column with the mean_x column. While the other function keeps the x column and has the mean_x column added too.
</p>

### Case study: aggregates and sample size

#### Whenever you do any aggregation, it’s always a good idea to include a count (n()). That way, you can ensure that you’re not drawing conclusions based on very small amounts of data. We’ll demonstrate this with some baseball data from the Lahman package. Specifically, we will compare what proportion of times a player gets a hit (H) vs. the number of times they try to put the ball in play (AB):

```{r case_study}

batters <- Lahman::Batting |> 
  group_by(playerID) |> 
  summarize(
    performance = sum(H, na.rm = TRUE) / sum(AB, na.rm = TRUE),
    n = sum(AB, na.rm = TRUE)
  )

batters

batters |> 
  filter(n > 100) |> 
  ggplot(aes(x = n, y = performance)) +
  geom_point(alpha = 1 / 10) +
  geom_smooth(se = FALSE) +
  labs(title = "Baseball Players")

batters |> 
  arrange(desc(performance))

```



